{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HW2-2020.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erkenyigit/blusearch/blob/master/Copy_of_HW2_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khfvm2ZTbxaF"
      },
      "source": [
        "# CS412 - Machine Learning - 2020\n",
        "\n",
        "# Homework 2\n",
        "\n",
        "100 pts\n",
        "\n",
        "# Goal\n",
        "\n",
        "The goal of this homework is to get familiar feature handling and cross validation.\n",
        "\n",
        "\n",
        "# Dataset\n",
        "\n",
        "German Credit Risk dataset, prepared by Prof. Hoffman, classifies each person as having a good or bad credit risk. The dataset that we use consists of both numerical and categorical features.\n",
        "\n",
        "\n",
        "\n",
        "# Task\n",
        "\n",
        "Build a k-NN classifier with scikit-learn library to classify people as bad or good risks for the german credit dataset. \n",
        "\n",
        "# Software\n",
        "\n",
        "Documentation for the necessary functions can be accessed from the link below.\n",
        "\n",
        "[http://scikit-learn.org/stable/supervised_learning.html](http://scikit-learn.org/stable/supervised_learning.html)\n",
        "\n",
        "# Submission\n",
        "\n",
        "Follow the instructions at the end.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WhAm9Ii-SH"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V99blGJZ02tQ",
        "outputId": "0a3f37b8-a11a-41fa-b445-5170026484bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount to your drive, in this way you can reach files that are in your drive\n",
        "# Run this cell\n",
        "# Go through the link that will be showed below\n",
        "# Select your google drive account and copy authorization code and paste here in output and press enter\n",
        "# You can also follow the steps from that link\n",
        "# https://medium.com/ml-book/simplest-way-to-open-files-from-google-drive-in-google-colab-fae14810674 \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLcZp_XKjp2N"
      },
      "source": [
        "# 2) Load Dataset\n",
        "\n",
        "To start working for your homework, take a copy of the folder, given in the below link to your own google drive. You find the train and test data under this folder.\n",
        "\n",
        "[https://drive.google.com/drive/folders/1DbW6VxLKZv2oqFn9SwxAnVadmn1_nPXi?usp=sharing](https://drive.google.com/drive/folders/1DbW6VxLKZv2oqFn9SwxAnVadmn1_nPXi?usp=sharing)\n",
        "\n",
        "After copy the folder, copy the path of the train and test dataset to paste them in the below cell to load your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSZvqTSTbsv8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('...')\n",
        "test_df = pd.read_csv('...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PwZVkZkCZQ"
      },
      "source": [
        "# 3) Optional - Analyze the Dataset \n",
        "\n",
        "You can use the functions of the pandas library to analyze your train dataset in detail - **this part is OPTIONAL - look around the data as you wish**.\n",
        "\n",
        "\n",
        "*   Display the number of instances and features in the train ***(shape function can be used)**\n",
        "*   Display 5 random examples from the train ***(sample function can be used)**\n",
        "*   Display the information about each features ***(info method can be used)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XdZUTLqkAw7"
      },
      "source": [
        "# Print shape\n",
        "print(\"Train data dimensionality: \", )\n",
        "\n",
        "# Print random 5 rows\n",
        "print(\"Examples from train data: \")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLL4s7GFsBVJ"
      },
      "source": [
        "# Print the information about the dataset\n",
        "print(\"Information about train data \", )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yVSSt0mtH0W"
      },
      "source": [
        "# 4) Define your train and test labels\n",
        "\n",
        "*  Define labels for both train and test data in new arrays \n",
        "*  And remove the label column from both train and test sets do tht it is not used as a feature! \n",
        "\n",
        "\n",
        "(**you can use pop method**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heg3V6IssehF"
      },
      "source": [
        "# Define labels\n",
        "train_label = \n",
        "test_label = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGw3v-ai4jTN"
      },
      "source": [
        "# 5) Handle missing values if any \n",
        "\n",
        "*   Print the columns that have **NaN** values (**isnull** method can be used)\n",
        "*   You can impute missing values with mode of that feature or remove samples or attributes\n",
        "*   To impute the test set, you should use the mode values that you obtain from **train** set, as **you should not be looking at your test data to gain any information or advantage.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNKte7c8EpR"
      },
      "source": [
        "# Print columns with NaN values\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd6s66xKLEiO"
      },
      "source": [
        "# Impute missing values by replacing with mode value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkgqFpyr2BrX"
      },
      "source": [
        "# 6) Transform categorical / ordinal features\n",
        "\n",
        "* Transform all categorical / ordinal features using the methods that you have learnt in lectures and recitation 4 for both train and test data\n",
        "* You saw the dictionary use for mapping in recitation. (You can use **replace function** to assign new values to the categories of a column).\n",
        "\n",
        "*  The class of the categorical attributes in the dataset are defined as follows:\n",
        "  - Status of existing checking account\n",
        "     - A11 :      ... <    0 DM\n",
        "\t- A12 : 0 <= ... <  200 DM\n",
        "\t- A13 :      ... >= 200 DM / salary assignments for at least 1 year\n",
        "     - A14 : no checking account\n",
        "\n",
        " - Credit history\n",
        "    - A30 : no credits taken/all credits paid back duly\n",
        "    - A31 : all credits at this bank paid back duly\n",
        "\t- A32 : existing credits paid back duly till now\n",
        "    - A33 : delay in paying off in the past\n",
        "\t- A34 : critical account/other credits existing (not at this bank)\n",
        "\n",
        "  - Savings account\n",
        "    - A61 :          ... <  100 DM\n",
        "\t- A62 :   100 <= ... <  500 DM\n",
        "\t- A63 :   500 <= ... < 1000 DM\n",
        "\t- A64 :          .. >= 1000 DM\n",
        "    - A65 :   unknown/ no savings account\n",
        "\n",
        " - Employment Since\n",
        "    - A71 : unemployed\n",
        "    - A72 :       ... < 1 year\n",
        "\t- A73 : 1  <= ... < 4 years  \n",
        "\t- A74 : 4  <= ... < 7 years\n",
        "\t- A75 :       .. >= 7 years\n",
        " \n",
        " - Personal Status\n",
        "    - A91 : male   : divorced/separated\n",
        "\t- A92 : female : divorced/separated/married\n",
        "    - A93 : male   : single\n",
        "\t- A94 : male   : married/widowed\n",
        "\t- A95 : female : single\n",
        "\n",
        "  - Property\n",
        "     -  A121 : real estate\n",
        "\t- A122 : if not A121 : building society savings agreement/life insurance\n",
        "    - A123 : if not A121/A122 : car or other, not in attribute 6\n",
        "\t- A124 : unknown / no property\n",
        "\n",
        " - OtherInstallPlans  \n",
        "    - A141 : bank\n",
        "\t- A142 : stores\n",
        "\t- A143 : none\n",
        "\n",
        " - Housing\n",
        "    -  A151 : rent\n",
        "\t - A152 : own\n",
        "\t- A153 : for free"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evng6_DyYevs"
      },
      "source": [
        "# Transform the categorical / ordinal attributes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVcTCh9-AnFv"
      },
      "source": [
        "# 7) Build a k-NN classifier on training data and perform models selection using 5 fold cross validation\n",
        "\n",
        "*  Initialize k-NN classifiers with **k= 5, 10, 15**\n",
        "*  Calculate the cross validation scores using cross_al_score method, number of folds is 5. \n",
        "*  Note: Xval is performed on training data! Do not use test data in any way and do not separate a hold-out validation set, rather use cross-validation.\n",
        "\n",
        "Documentation of the cross_val_score method:\n",
        "\n",
        "[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n",
        "\n",
        "*  Stores the average accuracies of these folds\n",
        "*  Select the value of k using the cross validation results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficAs0W52b8r"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "\n",
        "# k values\n",
        "kVals = [5,10,15]\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "accuracies = []\n",
        "\n",
        "# Loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Initialize a k-NN classifier with k neighbors\n",
        "  \n",
        "\n",
        "  # Calculate the 5 fold cross validation scores using cross_val_score\n",
        "  # cv parameter: number of folds, in our case it must be 5\n",
        "  scores = \n",
        "\n",
        "  # Stores the average accuracies of the scores in accuracies variable, you can use mean method\n",
        "\n",
        "\n",
        "print(accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t4ss1Ixglor"
      },
      "source": [
        "# 8) Retrain using all training data and test on test set\n",
        "\n",
        "* Train a classifier with the chosen k value of the best classifier using **all training data**. \n",
        "\n",
        "Note:  k-NN training involves no explicit training, but this is what we would do after model selection with decision trees or any other ML approach (we had 5 diff. models -one for each fold - for each k in the previous step - dont know which one to submit. Even if we picked the best one, it does not use all training samples.\n",
        "\n",
        "* Predict the labels of testing data \n",
        "\n",
        "* Report the accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi3pfvaBKTcg"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train the best classifier using all training set\n",
        "\n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "\n",
        "\n",
        "# Print accuracy of test data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4ZCEjEXiMGi"
      },
      "source": [
        "# 9) Bonus (5pts)\n",
        "\n",
        "There is a limited bonus for any extra work that you may use and improve the above results. \n",
        "\n",
        "You may try a larger k values, scale input features, remove some features, .... Please **do not overdo**, maybe spend another 30-60min on this. The idea is not do an exhaustive search (which wont help your understanding of ML process), but just to give some extra points to those who may look at the problem a little more comprehensively. \n",
        "\n",
        "**If you obtain better results than the above, please indicate the best model you have found and the corresponding accuracy.**\n",
        "\n",
        "E.g. using feature normalization ..... and removing .... features and using a value k=...., I have obtained ....% accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTnB4ZMviQGV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5AuzuKliQiY"
      },
      "source": [
        "# 10) Notebook & Report\n",
        "\n",
        "**Notebook:** We may just look at your notebook results; so make sure each cell is run and outputs are there.\n",
        "\n",
        "**Report:** Write an at most 1/2 page summary of your approach to this problem at the end of your notebook; this should be like an abstract of a paper or the executive summary.\n",
        "\n",
        "**Must include statements such as:**\n",
        "\n",
        "( Include the problem definition: 1-2 lines )\n",
        "\n",
        "(Talk about any preprocessing you do, How you handle missing values and categorical features)\n",
        "\n",
        "( Give the average validation accuracies for different k values and standard deviations between 5 folds of each k values, state which one you selected)\n",
        "\n",
        "( State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\"\"\n",
        "\n",
        "State if there is any **bonus** work...\n",
        "\n",
        "You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaPs6f7mkiI0"
      },
      "source": [
        "# 11) Submission\n",
        "\n",
        "Please submit your **\"share link\" INLINE in Sucourse submissions**. That is we should be able to click on the link and go there and run (and possibly also modify) your code. \n",
        "\n",
        "For us to be able to modify, in case of errors etc, **you should get your \"share link\" as **share with anyone in edit mode** \n",
        "\n",
        " **Also submit your notebook as pdf as attachment**, choose print and save as PDF, save with hw2-lastname-firstname.pdf to facilitate grading. \n"
      ]
    }
  ]
}